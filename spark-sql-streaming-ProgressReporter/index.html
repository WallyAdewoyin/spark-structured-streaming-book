<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Demystifying inner-workings of Spark Structured Streaming"><link href=https://jaceklaskowski.github.io/spark-structured-streaming-book/spark-sql-streaming-ProgressReporter/ rel=canonical><meta name=author content="Jacek Laskowski"><link rel="shortcut icon" href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-5.5.14"><title>ProgressReporter - The Internals of Spark Structured Streaming</title><link rel=stylesheet href=../assets/stylesheets/main.d3202873.min.css><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-151208281-3","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#source-scala class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://jaceklaskowski.github.io/spark-structured-streaming-book/ title="The Internals of Spark Structured Streaming" class="md-header-nav__button md-logo" aria-label="The Internals of Spark Structured Streaming"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> The Internals of Spark Structured Streaming </span> <span class="md-header-nav__topic md-ellipsis"> ProgressReporter </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-structured-streaming-book </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class="md-tabs md-tabs--active" aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class="md-tabs__link md-tabs__link--active"> Home </a> </li> <li class=md-tabs__item> <a href=../operators/ class=md-tabs__link> Streaming Operators </a> </li> <li class=md-tabs__item> <a href=../spark-sql-streaming-FileStreamSource/ class=md-tabs__link> Data Sources </a> </li> <li class=md-tabs__item> <a href=../demo/spark-sql-streaming-demo-FlatMapGroupsWithStateExec/ class=md-tabs__link> Demos </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://jaceklaskowski.github.io/spark-structured-streaming-book/ title="The Internals of Spark Structured Streaming" class="md-nav__button md-logo" aria-label="The Internals of Spark Structured Streaming"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> The Internals of Spark Structured Streaming </label> <div class=md-nav__source> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-structured-streaming-book </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1 type=checkbox id=nav-1 checked> <label class=md-nav__link for=nav-1> Home <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Home data-md-level=1> <label class=md-nav__title for=nav-1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. title=Welcome class=md-nav__link> Welcome </a> </li> <li class=md-nav__item> <a href=../spark-structured-streaming/ title="Spark Structured Streaming and Streaming Queries" class=md-nav__link> Spark Structured Streaming and Streaming Queries </a> </li> <li class=md-nav__item> <a href=../spark-structured-streaming-batch-processing-time/ title="Batch Processing Time" class=md-nav__link> Batch Processing Time </a> </li> <li class=md-nav__item> <a href=../spark-structured-streaming-internals/ title="Internals of Streaming Queries" class=md-nav__link> Internals of Streaming Queries </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-5 type=checkbox id=nav-1-5> <label class=md-nav__link for=nav-1-5> Streaming Join <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Streaming Join" data-md-level=2> <label class=md-nav__title for=nav-1-5> <span class="md-nav__icon md-icon"></span> Streaming Join </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-join/ title="Streaming Join" class=md-nav__link> Streaming Join </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreAwareZipPartitionsRDD/ title=StateStoreAwareZipPartitionsRDD class=md-nav__link> StateStoreAwareZipPartitionsRDD </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-5-3 type=checkbox id=nav-1-5-3> <label class=md-nav__link for=nav-1-5-3> SymmetricHashJoinStateManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SymmetricHashJoinStateManager data-md-level=3> <label class=md-nav__title for=nav-1-5-3> <span class="md-nav__icon md-icon"></span> SymmetricHashJoinStateManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-SymmetricHashJoinStateManager/ title=SymmetricHashJoinStateManager class=md-nav__link> SymmetricHashJoinStateManager </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreHandler/ title=StateStoreHandler class=md-nav__link> StateStoreHandler </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KeyToNumValuesStore/ title=KeyToNumValuesStore class=md-nav__link> KeyToNumValuesStore </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KeyWithIndexToValueStore/ title=KeyWithIndexToValueStore class=md-nav__link> KeyWithIndexToValueStore </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-OneSideHashJoiner/ title=OneSideHashJoiner class=md-nav__link> OneSideHashJoiner </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-JoinStateWatermarkPredicates/ title=JoinStateWatermarkPredicates class=md-nav__link> JoinStateWatermarkPredicates </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-JoinStateWatermarkPredicate/ title=JoinStateWatermarkPredicate class=md-nav__link> JoinStateWatermarkPredicate </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-5-7 type=checkbox id=nav-1-5-7> <label class=md-nav__link for=nav-1-5-7> StateStoreAwareZipPartitionsHelper <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreAwareZipPartitionsHelper data-md-level=3> <label class=md-nav__title for=nav-1-5-7> <span class="md-nav__icon md-icon"></span> StateStoreAwareZipPartitionsHelper </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreAwareZipPartitionsHelper/ title=StateStoreAwareZipPartitionsHelper class=md-nav__link> StateStoreAwareZipPartitionsHelper </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingSymmetricHashJoinHelper/ title=StreamingSymmetricHashJoinHelper class=md-nav__link> StreamingSymmetricHashJoinHelper </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingJoinHelper/ title=StreamingJoinHelper class=md-nav__link> StreamingJoinHelper </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-6 type=checkbox id=nav-1-6> <label class=md-nav__link for=nav-1-6> Extending Structured Streaming with New Data Sources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Extending Structured Streaming with New Data Sources" data-md-level=2> <label class=md-nav__title for=nav-1-6> <span class="md-nav__icon md-icon"></span> Extending Structured Streaming with New Data Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-extending-new-data-sources/ title="Extending Structured Streaming with New Data Sources" class=md-nav__link> Extending Structured Streaming with New Data Sources </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-BaseStreamingSource/ title=BaseStreamingSource class=md-nav__link> BaseStreamingSource </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-BaseStreamingSink/ title=BaseStreamingSink class=md-nav__link> BaseStreamingSink </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamWriteSupport/ title=StreamWriteSupport class=md-nav__link> StreamWriteSupport </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamWriter/ title=StreamWriter class=md-nav__link> StreamWriter </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-DataSource/ title=DataSource class=md-nav__link> DataSource </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-7 type=checkbox id=nav-1-7> <label class=md-nav__link for=nav-1-7> Streaming Aggregation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Streaming Aggregation" data-md-level=2> <label class=md-nav__title for=nav-1-7> <span class="md-nav__icon md-icon"></span> Streaming Aggregation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-aggregation/ title="Streaming Aggregation" class=md-nav__link> Streaming Aggregation </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreRDD/ title=StateStoreRDD class=md-nav__link> StateStoreRDD </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreOps/ title=StateStoreOps class=md-nav__link> StateStoreOps </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingAggregationStateManager/ title=StreamingAggregationStateManager class=md-nav__link> StreamingAggregationStateManager </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingAggregationStateManagerBaseImpl/ title=StreamingAggregationStateManagerBaseImpl class=md-nav__link> StreamingAggregationStateManagerBaseImpl </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingAggregationStateManagerImplV1/ title=StreamingAggregationStateManagerImplV1 class=md-nav__link> StreamingAggregationStateManagerImplV1 </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingAggregationStateManagerImplV2/ title=StreamingAggregationStateManagerImplV2 class=md-nav__link> StreamingAggregationStateManagerImplV2 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8 type=checkbox id=nav-1-8> <label class=md-nav__link for=nav-1-8> Stateful Stream Processing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Stateful Stream Processing" data-md-level=2> <label class=md-nav__title for=nav-1-8> <span class="md-nav__icon md-icon"></span> Stateful Stream Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-stateful-stream-processing/ title="Stateful Stream Processing" class=md-nav__link> Stateful Stream Processing </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-watermark/ title="Streaming Watermark" class=md-nav__link> Streaming Watermark </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-deduplication/ title="Streaming Deduplication" class=md-nav__link> Streaming Deduplication </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-limit/ title="Streaming Limit" class=md-nav__link> Streaming Limit </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8-5 type=checkbox id=nav-1-8-5> <label class=md-nav__link for=nav-1-8-5> StateStore <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStore data-md-level=3> <label class=md-nav__title for=nav-1-8-5> <span class="md-nav__icon md-icon"></span> StateStore </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStore/ title=StateStore class=md-nav__link> StateStore </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreId/ title=StateStoreId class=md-nav__link> StateStoreId </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-HDFSBackedStateStore/ title=HDFSBackedStateStore class=md-nav__link> HDFSBackedStateStore </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8-6 type=checkbox id=nav-1-8-6> <label class=md-nav__link for=nav-1-8-6> StateStoreProvider <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreProvider data-md-level=3> <label class=md-nav__title for=nav-1-8-6> <span class="md-nav__icon md-icon"></span> StateStoreProvider </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreProvider/ title=StateStoreProvider class=md-nav__link> StateStoreProvider </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreProviderId/ title=StateStoreProviderId class=md-nav__link> StateStoreProviderId </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-HDFSBackedStateStoreProvider/ title=HDFSBackedStateStoreProvider class=md-nav__link> HDFSBackedStateStoreProvider </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8-7 type=checkbox id=nav-1-8-7> <label class=md-nav__link for=nav-1-8-7> StateStoreCoordinator <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateStoreCoordinator data-md-level=3> <label class=md-nav__title for=nav-1-8-7> <span class="md-nav__icon md-icon"></span> StateStoreCoordinator </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreCoordinator/ title=StateStoreCoordinator class=md-nav__link> StateStoreCoordinator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreCoordinatorRef/ title=StateStoreCoordinatorRef class=md-nav__link> StateStoreCoordinatorRef </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-WatermarkSupport/ title=WatermarkSupport class=md-nav__link> WatermarkSupport </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8-9 type=checkbox id=nav-1-8-9> <label class=md-nav__link for=nav-1-8-9> StatefulOperator <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StatefulOperator data-md-level=3> <label class=md-nav__title for=nav-1-8-9> <span class="md-nav__icon md-icon"></span> StatefulOperator </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StatefulOperator/ title=StatefulOperator class=md-nav__link> StatefulOperator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreReader/ title=StateStoreReader class=md-nav__link> StateStoreReader </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreWriter/ title=StateStoreWriter class=md-nav__link> StateStoreWriter </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StatefulOperatorStateInfo/ title=StatefulOperatorStateInfo class=md-nav__link> StatefulOperatorStateInfo </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreMetrics/ title=StateStoreMetrics class=md-nav__link> StateStoreMetrics </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreCustomMetric/ title=StateStoreCustomMetric class=md-nav__link> StateStoreCustomMetric </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreUpdater/ title=StateStoreUpdater class=md-nav__link> StateStoreUpdater </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-EventTimeStatsAccum/ title=EventTimeStatsAccum class=md-nav__link> EventTimeStatsAccum </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreConf/ title=StateStoreConf class=md-nav__link> StateStoreConf </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-9 type=checkbox id=nav-1-9> <label class=md-nav__link for=nav-1-9> Arbitrary Stateful Streaming Aggregation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Arbitrary Stateful Streaming Aggregation" data-md-level=2> <label class=md-nav__title for=nav-1-9> <span class="md-nav__icon md-icon"></span> Arbitrary Stateful Streaming Aggregation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../arbitrary-stateful-streaming-aggregation/ title="Arbitrary Stateful Streaming Aggregation" class=md-nav__link> Arbitrary Stateful Streaming Aggregation </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-9-2 type=checkbox id=nav-1-9-2> <label class=md-nav__link for=nav-1-9-2> KeyValueGroupedDataset <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KeyValueGroupedDataset data-md-level=3> <label class=md-nav__title for=nav-1-9-2> <span class="md-nav__icon md-icon"></span> KeyValueGroupedDataset </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../KeyValueGroupedDataset/ title=KeyValueGroupedDataset class=md-nav__link> KeyValueGroupedDataset </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KeyValueGroupedDataset-mapGroupsWithState/ title="mapGroupsWithState Operator" class=md-nav__link> mapGroupsWithState Operator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KeyValueGroupedDataset-flatMapGroupsWithState/ title="flatMapGroupsWithState Operator" class=md-nav__link> flatMapGroupsWithState Operator </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-9-3 type=checkbox id=nav-1-9-3> <label class=md-nav__link for=nav-1-9-3> GroupState <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=GroupState data-md-level=3> <label class=md-nav__title for=nav-1-9-3> <span class="md-nav__icon md-icon"></span> GroupState </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../GroupState/ title=GroupState class=md-nav__link> GroupState </a> </li> <li class=md-nav__item> <a href=../GroupStateImpl/ title=GroupStateImpl class=md-nav__link> GroupStateImpl </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-GroupStateTimeout/ title=GroupStateTimeout class=md-nav__link> GroupStateTimeout </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-9-5 type=checkbox id=nav-1-9-5> <label class=md-nav__link for=nav-1-9-5> StateManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StateManager data-md-level=3> <label class=md-nav__title for=nav-1-9-5> <span class="md-nav__icon md-icon"></span> StateManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StateManager/ title=StateManager class=md-nav__link> StateManager </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateManagerImplV2/ title=StateManagerImplV2 class=md-nav__link> StateManagerImplV2 </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateManagerImplBase/ title=StateManagerImplBase class=md-nav__link> StateManagerImplBase </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateManagerImplV1/ title=StateManagerImplV1 class=md-nav__link> StateManagerImplV1 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-FlatMapGroupsWithStateExecHelper/ title="FlatMapGroupsWithStateExecHelper Helper Class" class=md-nav__link> FlatMapGroupsWithStateExecHelper Helper Class </a> </li> <li class=md-nav__item> <a href=../InputProcessor/ title=InputProcessor class=md-nav__link> InputProcessor </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-10 type=checkbox id=nav-1-10> <label class=md-nav__link for=nav-1-10> Developing Streaming Applications <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Developing Streaming Applications" data-md-level=2> <label class=md-nav__title for=nav-1-10> <span class="md-nav__icon md-icon"></span> Developing Streaming Applications </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-DataStreamReader/ title=DataStreamReader class=md-nav__link> DataStreamReader </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-10-2 type=checkbox id=nav-1-10-2> <label class=md-nav__link for=nav-1-10-2> DataStreamWriter <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=DataStreamWriter data-md-level=3> <label class=md-nav__title for=nav-1-10-2> <span class="md-nav__icon md-icon"></span> DataStreamWriter </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../DataStreamWriter/ title=DataStreamWriter class=md-nav__link> DataStreamWriter </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-OutputMode/ title=OutputMode class=md-nav__link> OutputMode </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-Trigger/ title=Trigger class=md-nav__link> Trigger </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingQuery/ title=StreamingQuery class=md-nav__link> StreamingQuery </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-window/ title="window Function" class=md-nav__link> window Function </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingQueryManager/ title=StreamingQueryManager class=md-nav__link> StreamingQueryManager </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-SQLConf/ title=SQLConf class=md-nav__link> SQLConf </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-properties/ title="Configuration Properties" class=md-nav__link> Configuration Properties </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-11 type=checkbox id=nav-1-11 checked> <label class=md-nav__link for=nav-1-11> Monitoring of Streaming Query Execution <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Monitoring of Streaming Query Execution" data-md-level=2> <label class=md-nav__title for=nav-1-11> <span class="md-nav__icon md-icon"></span> Monitoring of Streaming Query Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingQueryListener/ title=StreamingQueryListener class=md-nav__link> StreamingQueryListener </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <a href=./ title=ProgressReporter class="md-nav__link md-nav__link--active"> ProgressReporter </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-11-3 type=checkbox id=nav-1-11-3> <label class=md-nav__link for=nav-1-11-3> StreamingQueryProgress <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StreamingQueryProgress data-md-level=3> <label class=md-nav__title for=nav-1-11-3> <span class="md-nav__icon md-icon"></span> StreamingQueryProgress </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingQueryProgress/ title=StreamingQueryProgress class=md-nav__link> StreamingQueryProgress </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ExecutionStats/ title=ExecutionStats class=md-nav__link> ExecutionStats </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-SourceProgress/ title=SourceProgress class=md-nav__link> SourceProgress </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-SinkProgress/ title=SinkProgress class=md-nav__link> SinkProgress </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingQueryStatus/ title=StreamingQueryStatus class=md-nav__link> StreamingQueryStatus </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MetricsReporter/ title=MetricsReporter class=md-nav__link> MetricsReporter </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-webui/ title="Web UI" class=md-nav__link> Web UI </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-logging/ title=Logging class=md-nav__link> Logging </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-12 type=checkbox id=nav-1-12> <label class=md-nav__link for=nav-1-12> Query Planning and Execution <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Query Planning and Execution" data-md-level=2> <label class=md-nav__title for=nav-1-12> <span class="md-nav__icon md-icon"></span> Query Planning and Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-12-1 type=checkbox id=nav-1-12-1> <label class=md-nav__link for=nav-1-12-1> StreamExecution <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=StreamExecution data-md-level=3> <label class=md-nav__title for=nav-1-12-1> <span class="md-nav__icon md-icon"></span> StreamExecution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamExecution/ title=StreamExecution class=md-nav__link> StreamExecution </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingQueryWrapper/ title=StreamingQueryWrapper class=md-nav__link> StreamingQueryWrapper </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-TriggerExecutor/ title=TriggerExecutor class=md-nav__link> TriggerExecutor </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-IncrementalExecution/ title=IncrementalExecution class=md-nav__link> IncrementalExecution </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingQueryListenerBus/ title=StreamingQueryListenerBus class=md-nav__link> StreamingQueryListenerBus </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamMetadata/ title=StreamMetadata class=md-nav__link> StreamMetadata </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-12-6 type=checkbox id=nav-1-12-6> <label class=md-nav__link for=nav-1-12-6> Logical Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Logical Operators" data-md-level=3> <label class=md-nav__title for=nav-1-12-6> <span class="md-nav__icon md-icon"></span> Logical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-EventTimeWatermark/ title="EventTimeWatermark Unary Logical Operator" class=md-nav__link> EventTimeWatermark Unary Logical Operator </a> </li> <li class=md-nav__item> <a href=../logical-operators/FlatMapGroupsWithState/ title="FlatMapGroupsWithState Unary Logical Operator" class=md-nav__link> FlatMapGroupsWithState Unary Logical Operator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-Deduplicate/ title="Deduplicate Unary Logical Operator" class=md-nav__link> Deduplicate Unary Logical Operator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MemoryPlan/ title="MemoryPlan Logical Query Plan" class=md-nav__link> MemoryPlan Logical Query Plan </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingRelation/ title="StreamingRelation Leaf Logical Operator for Streaming Source" class=md-nav__link> StreamingRelation Leaf Logical Operator for Streaming Source </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingRelationV2/ title="StreamingRelationV2 Leaf Logical Operator" class=md-nav__link> StreamingRelationV2 Leaf Logical Operator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingExecutionRelation/ title="StreamingExecutionRelation Leaf Logical Operator for Streaming Source At Execution" class=md-nav__link> StreamingExecutionRelation Leaf Logical Operator for Streaming Source At Execution </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-12-7 type=checkbox id=nav-1-12-7> <label class=md-nav__link for=nav-1-12-7> Physical Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Physical Operators" data-md-level=3> <label class=md-nav__title for=nav-1-12-7> <span class="md-nav__icon md-icon"></span> Physical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-EventTimeWatermarkExec/ title=EventTimeWatermarkExec class=md-nav__link> EventTimeWatermarkExec </a> </li> <li class=md-nav__item> <a href=../physical-operators/FlatMapGroupsWithStateExec/ title=FlatMapGroupsWithStateExec class=md-nav__link> FlatMapGroupsWithStateExec </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreRestoreExec/ title=StateStoreRestoreExec class=md-nav__link> StateStoreRestoreExec </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StateStoreSaveExec/ title=StateStoreSaveExec class=md-nav__link> StateStoreSaveExec </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingDeduplicateExec/ title=StreamingDeduplicateExec class=md-nav__link> StreamingDeduplicateExec </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingGlobalLimitExec/ title=StreamingGlobalLimitExec class=md-nav__link> StreamingGlobalLimitExec </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingRelationExec/ title=StreamingRelationExec class=md-nav__link> StreamingRelationExec </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingSymmetricHashJoinExec/ title=StreamingSymmetricHashJoinExec class=md-nav__link> StreamingSymmetricHashJoinExec </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-12-8 type=checkbox id=nav-1-12-8> <label class=md-nav__link for=nav-1-12-8> Execution Planning Strategies <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Execution Planning Strategies" data-md-level=3> <label class=md-nav__title for=nav-1-12-8> <span class="md-nav__icon md-icon"></span> Execution Planning Strategies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-FlatMapGroupsWithStateStrategy/ title=FlatMapGroupsWithStateStrategy class=md-nav__link> FlatMapGroupsWithStateStrategy </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StatefulAggregationStrategy/ title=StatefulAggregationStrategy class=md-nav__link> StatefulAggregationStrategy </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingDeduplicationStrategy/ title=StreamingDeduplicationStrategy class=md-nav__link> StreamingDeduplicationStrategy </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingGlobalLimitStrategy/ title=StreamingGlobalLimitStrategy class=md-nav__link> StreamingGlobalLimitStrategy </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingJoinStrategy/ title=StreamingJoinStrategy class=md-nav__link> StreamingJoinStrategy </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamingRelationStrategy/ title=StreamingRelationStrategy class=md-nav__link> StreamingRelationStrategy </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-13 type=checkbox id=nav-1-13> <label class=md-nav__link for=nav-1-13> Offsets and Metadata Checkpointing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Offsets and Metadata Checkpointing" data-md-level=2> <label class=md-nav__title for=nav-1-13> <span class="md-nav__icon md-icon"></span> Offsets and Metadata Checkpointing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-offsets-and-metadata-checkpointing/ title="Offsets and Metadata Checkpointing" class=md-nav__link> Offsets and Metadata Checkpointing </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MetadataLog/ title=MetadataLog class=md-nav__link> MetadataLog </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-HDFSMetadataLog/ title=HDFSMetadataLog class=md-nav__link> HDFSMetadataLog </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-13-4 type=checkbox id=nav-1-13-4> <label class=md-nav__link for=nav-1-13-4> CommitLog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CommitLog data-md-level=3> <label class=md-nav__title for=nav-1-13-4> <span class="md-nav__icon md-icon"></span> CommitLog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-CommitLog/ title=CommitLog class=md-nav__link> CommitLog </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-CommitMetadata/ title=CommitMetadata class=md-nav__link> CommitMetadata </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-13-5 type=checkbox id=nav-1-13-5> <label class=md-nav__link for=nav-1-13-5> OffsetSeqLog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=OffsetSeqLog data-md-level=3> <label class=md-nav__title for=nav-1-13-5> <span class="md-nav__icon md-icon"></span> OffsetSeqLog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-OffsetSeqLog/ title=OffsetSeqLog class=md-nav__link> OffsetSeqLog </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-OffsetSeq/ title=OffsetSeq class=md-nav__link> OffsetSeq </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-13-6 type=checkbox id=nav-1-13-6> <label class=md-nav__link for=nav-1-13-6> CompactibleFileStreamLog <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CompactibleFileStreamLog data-md-level=3> <label class=md-nav__title for=nav-1-13-6> <span class="md-nav__icon md-icon"></span> CompactibleFileStreamLog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-CompactibleFileStreamLog/ title=CompactibleFileStreamLog class=md-nav__link> CompactibleFileStreamLog </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-FileStreamSourceLog/ title=FileStreamSourceLog class=md-nav__link> FileStreamSourceLog </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-OffsetSeqMetadata/ title=OffsetSeqMetadata class=md-nav__link> OffsetSeqMetadata </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-13-8 type=checkbox id=nav-1-13-8> <label class=md-nav__link for=nav-1-13-8> CheckpointFileManager <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CheckpointFileManager data-md-level=3> <label class=md-nav__title for=nav-1-13-8> <span class="md-nav__icon md-icon"></span> CheckpointFileManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-CheckpointFileManager/ title=CheckpointFileManager class=md-nav__link> CheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-FileContextBasedCheckpointFileManager/ title=FileContextBasedCheckpointFileManager class=md-nav__link> FileContextBasedCheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-FileSystemBasedCheckpointFileManager/ title=FileSystemBasedCheckpointFileManager class=md-nav__link> FileSystemBasedCheckpointFileManager </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-Offset/ title=Offset class=md-nav__link> Offset </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamProgress/ title=StreamProgress class=md-nav__link> StreamProgress </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-14 type=checkbox id=nav-1-14> <label class=md-nav__link for=nav-1-14> Micro-Batch Stream Processing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Micro-Batch Stream Processing" data-md-level=2> <label class=md-nav__title for=nav-1-14> <span class="md-nav__icon md-icon"></span> Micro-Batch Stream Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-micro-batch-stream-processing/ title="Micro-Batch Stream Processing" class=md-nav__link> Micro-Batch Stream Processing </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-14-2 type=checkbox id=nav-1-14-2> <label class=md-nav__link for=nav-1-14-2> MicroBatchExecution <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=MicroBatchExecution data-md-level=3> <label class=md-nav__title for=nav-1-14-2> <span class="md-nav__icon md-icon"></span> MicroBatchExecution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-MicroBatchExecution/ title=MicroBatchExecution class=md-nav__link> MicroBatchExecution </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MicroBatchWriter/ title=MicroBatchWriter class=md-nav__link> MicroBatchWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-14-3 type=checkbox id=nav-1-14-3> <label class=md-nav__link for=nav-1-14-3> MicroBatchReadSupport <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=MicroBatchReadSupport data-md-level=3> <label class=md-nav__title for=nav-1-14-3> <span class="md-nav__icon md-icon"></span> MicroBatchReadSupport </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-MicroBatchReadSupport/ title=MicroBatchReadSupport class=md-nav__link> MicroBatchReadSupport </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MicroBatchReader/ title=MicroBatchReader class=md-nav__link> MicroBatchReader </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-WatermarkTracker/ title=WatermarkTracker class=md-nav__link> WatermarkTracker </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-14-5 type=checkbox id=nav-1-14-5> <label class=md-nav__link for=nav-1-14-5> Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Source data-md-level=3> <label class=md-nav__title for=nav-1-14-5> <span class="md-nav__icon md-icon"></span> Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Source/ title=Source class=md-nav__link> Source </a> </li> <li class=md-nav__item> <a href=../StreamSourceProvider/ title=StreamSourceProvider class=md-nav__link> StreamSourceProvider </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-14-6 type=checkbox id=nav-1-14-6> <label class=md-nav__link for=nav-1-14-6> Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Sink data-md-level=3> <label class=md-nav__title for=nav-1-14-6> <span class="md-nav__icon md-icon"></span> Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-Sink/ title=Sink class=md-nav__link> Sink </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-StreamSinkProvider/ title=StreamSinkProvider class=md-nav__link> StreamSinkProvider </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15 type=checkbox id=nav-1-15> <label class=md-nav__link for=nav-1-15> Continuous Stream Processing <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Continuous Stream Processing" data-md-level=2> <label class=md-nav__title for=nav-1-15> <span class="md-nav__icon md-icon"></span> Continuous Stream Processing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-continuous-stream-processing/ title="Continuous Stream Processing" class=md-nav__link> Continuous Stream Processing </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousExecution/ title=ContinuousExecution class=md-nav__link> ContinuousExecution </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousReadSupport/ title="ContinuousReadSupport Contract" class=md-nav__link> ContinuousReadSupport Contract </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousReader/ title="ContinuousReader Contract" class=md-nav__link> ContinuousReader Contract </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-RateStreamContinuousReader/ title=RateStreamContinuousReader class=md-nav__link> RateStreamContinuousReader </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15-6 type=checkbox id=nav-1-15-6> <label class=md-nav__link for=nav-1-15-6> EpochCoordinator <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=EpochCoordinator data-md-level=3> <label class=md-nav__title for=nav-1-15-6> <span class="md-nav__icon md-icon"></span> EpochCoordinator </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-EpochCoordinator/ title="EpochCoordinator RPC Endpoint" class=md-nav__link> EpochCoordinator RPC Endpoint </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-EpochCoordinatorRef/ title=EpochCoordinatorRef class=md-nav__link> EpochCoordinatorRef </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-EpochTracker/ title=EpochTracker class=md-nav__link> EpochTracker </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15-7 type=checkbox id=nav-1-15-7> <label class=md-nav__link for=nav-1-15-7> ContinuousQueuedDataReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=ContinuousQueuedDataReader data-md-level=3> <label class=md-nav__title for=nav-1-15-7> <span class="md-nav__icon md-icon"></span> ContinuousQueuedDataReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousQueuedDataReader/ title=ContinuousQueuedDataReader class=md-nav__link> ContinuousQueuedDataReader </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousQueuedDataReader-DataReaderThread/ title=DataReaderThread class=md-nav__link> DataReaderThread </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousQueuedDataReader-EpochMarkerGenerator/ title=EpochMarkerGenerator class=md-nav__link> EpochMarkerGenerator </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-PartitionOffset/ title=PartitionOffset class=md-nav__link> PartitionOffset </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousExecutionRelation/ title="ContinuousExecutionRelation Leaf Logical Operator" class=md-nav__link> ContinuousExecutionRelation Leaf Logical Operator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-WriteToContinuousDataSource/ title="WriteToContinuousDataSource Unary Logical Operator" class=md-nav__link> WriteToContinuousDataSource Unary Logical Operator </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15-11 type=checkbox id=nav-1-15-11> <label class=md-nav__link for=nav-1-15-11> WriteToContinuousDataSourceExec <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=WriteToContinuousDataSourceExec data-md-level=3> <label class=md-nav__title for=nav-1-15-11> <span class="md-nav__icon md-icon"></span> WriteToContinuousDataSourceExec </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-WriteToContinuousDataSourceExec/ title="WriteToContinuousDataSourceExec Unary Physical Operator" class=md-nav__link> WriteToContinuousDataSourceExec Unary Physical Operator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousWriteRDD/ title=ContinuousWriteRDD class=md-nav__link> ContinuousWriteRDD </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousDataSourceRDD/ title=ContinuousDataSourceRDD class=md-nav__link> ContinuousDataSourceRDD </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-UnsupportedOperationChecker/ title=UnsupportedOperationChecker class=md-nav__link> UnsupportedOperationChecker </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Streaming Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Streaming Operators" data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"></span> Streaming Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../operators/ title="Streaming Operators" class=md-nav__link> Streaming Operators </a> </li> <li class=md-nav__item> <a href=../operators/crossJoin/ title=crossJoin class=md-nav__link> crossJoin </a> </li> <li class=md-nav__item> <a href=../operators/dropDuplicates/ title=dropDuplicates class=md-nav__link> dropDuplicates </a> </li> <li class=md-nav__item> <a href=../operators/explain/ title=explain class=md-nav__link> explain </a> </li> <li class=md-nav__item> <a href=../operators/groupBy/ title=groupBy class=md-nav__link> groupBy </a> </li> <li class=md-nav__item> <a href=../operators/groupByKey/ title=groupByKey class=md-nav__link> groupByKey </a> </li> <li class=md-nav__item> <a href=../operators/join/ title=join class=md-nav__link> join </a> </li> <li class=md-nav__item> <a href=../operators/joinWith/ title=joinWith class=md-nav__link> joinWith </a> </li> <li class=md-nav__item> <a href=../operators/withWatermark/ title=withWatermark class=md-nav__link> withWatermark </a> </li> <li class=md-nav__item> <a href=../operators/writeStream/ title=writeStream class=md-nav__link> writeStream </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Data Sources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Data Sources" data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"></span> Data Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-1 type=checkbox id=nav-3-1> <label class=md-nav__link for=nav-3-1> File-Based Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="File-Based Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-1> <span class="md-nav__icon md-icon"></span> File-Based Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-FileStreamSource/ title=FileStreamSource class=md-nav__link> FileStreamSource </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-FileStreamSink/ title=FileStreamSink class=md-nav__link> FileStreamSink </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-FileStreamSinkLog/ title=FileStreamSinkLog class=md-nav__link> FileStreamSinkLog </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-SinkFileStatus/ title=SinkFileStatus class=md-nav__link> SinkFileStatus </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ManifestFileCommitProtocol/ title=ManifestFileCommitProtocol class=md-nav__link> ManifestFileCommitProtocol </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MetadataLogFileIndex/ title=MetadataLogFileIndex class=md-nav__link> MetadataLogFileIndex </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-2 type=checkbox id=nav-3-2> <label class=md-nav__link for=nav-3-2> Kafka Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Kafka Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-2> <span class="md-nav__icon md-icon"></span> Kafka Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-kafka-data-source/ title="Kafka Data Source" class=md-nav__link> Kafka Data Source </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaSourceProvider/ title=KafkaSourceProvider class=md-nav__link> KafkaSourceProvider </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaSource/ title=KafkaSource class=md-nav__link> KafkaSource </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaRelation/ title=KafkaRelation class=md-nav__link> KafkaRelation </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaSourceRDD/ title=KafkaSourceRDD class=md-nav__link> KafkaSourceRDD </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-CachedKafkaConsumer/ title=CachedKafkaConsumer class=md-nav__link> CachedKafkaConsumer </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaSourceOffset/ title=KafkaSourceOffset class=md-nav__link> KafkaSourceOffset </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaOffsetReader/ title=KafkaOffsetReader class=md-nav__link> KafkaOffsetReader </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ConsumerStrategy/ title=ConsumerStrategy class=md-nav__link> ConsumerStrategy </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaSink/ title=KafkaSink class=md-nav__link> KafkaSink </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaOffsetRangeLimit/ title=KafkaOffsetRangeLimit class=md-nav__link> KafkaOffsetRangeLimit </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaDataConsumer/ title=KafkaDataConsumer class=md-nav__link> KafkaDataConsumer </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-2-13 type=checkbox id=nav-3-2-13> <label class=md-nav__link for=nav-3-2-13> KafkaMicroBatchReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KafkaMicroBatchReader data-md-level=3> <label class=md-nav__title for=nav-3-2-13> <span class="md-nav__icon md-icon"></span> KafkaMicroBatchReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaMicroBatchReader/ title=KafkaMicroBatchReader class=md-nav__link> KafkaMicroBatchReader </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaOffsetRangeCalculator/ title=KafkaOffsetRangeCalculator class=md-nav__link> KafkaOffsetRangeCalculator </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaMicroBatchInputPartition/ title=KafkaMicroBatchInputPartition class=md-nav__link> KafkaMicroBatchInputPartition </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaMicroBatchInputPartitionReader/ title=KafkaMicroBatchInputPartitionReader class=md-nav__link> KafkaMicroBatchInputPartitionReader </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaSourceInitialOffsetWriter/ title=KafkaSourceInitialOffsetWriter class=md-nav__link> KafkaSourceInitialOffsetWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-2-14 type=checkbox id=nav-3-2-14> <label class=md-nav__link for=nav-3-2-14> KafkaContinuousReader <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=KafkaContinuousReader data-md-level=3> <label class=md-nav__title for=nav-3-2-14> <span class="md-nav__icon md-icon"></span> KafkaContinuousReader </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaContinuousReader/ title=KafkaContinuousReader class=md-nav__link> KafkaContinuousReader </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-KafkaContinuousInputPartition/ title=KafkaContinuousInputPartition class=md-nav__link> KafkaContinuousInputPartition </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-3 type=checkbox id=nav-3-3> <label class=md-nav__link for=nav-3-3> Text Socket Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Text Socket Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-3> <span class="md-nav__icon md-icon"></span> Text Socket Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-TextSocketSourceProvider/ title=TextSocketSourceProvider class=md-nav__link> TextSocketSourceProvider </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-TextSocketSource/ title=TextSocketSource class=md-nav__link> TextSocketSource </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-4 type=checkbox id=nav-3-4> <label class=md-nav__link for=nav-3-4> Rate Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Rate Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-4> <span class="md-nav__icon md-icon"></span> Rate Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-RateSourceProvider/ title=RateSourceProvider class=md-nav__link> RateSourceProvider </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-RateStreamProvider/ title=RateStreamProvider class=md-nav__link> RateStreamProvider </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-RateStreamSource/ title=RateStreamSource class=md-nav__link> RateStreamSource </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-RateStreamMicroBatchReader/ title=RateStreamMicroBatchReader class=md-nav__link> RateStreamMicroBatchReader </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-5 type=checkbox id=nav-3-5> <label class=md-nav__link for=nav-3-5> Console Data Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Console Data Sink" data-md-level=2> <label class=md-nav__title for=nav-3-5> <span class="md-nav__icon md-icon"></span> Console Data Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-ConsoleSinkProvider/ title=ConsoleSinkProvider class=md-nav__link> ConsoleSinkProvider </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ConsoleWriter/ title=ConsoleWriter class=md-nav__link> ConsoleWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-6 type=checkbox id=nav-3-6> <label class=md-nav__link for=nav-3-6> Foreach Data Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Foreach Data Sink" data-md-level=2> <label class=md-nav__title for=nav-3-6> <span class="md-nav__icon md-icon"></span> Foreach Data Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-ForeachWriterProvider/ title=ForeachWriterProvider class=md-nav__link> ForeachWriterProvider </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ForeachWriter/ title=ForeachWriter class=md-nav__link> ForeachWriter </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ForeachSink/ title=ForeachSink class=md-nav__link> ForeachSink </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-7 type=checkbox id=nav-3-7> <label class=md-nav__link for=nav-3-7> ForeachBatch Data Sink <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="ForeachBatch Data Sink" data-md-level=2> <label class=md-nav__title for=nav-3-7> <span class="md-nav__icon md-icon"></span> ForeachBatch Data Sink </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-ForeachBatchSink/ title=ForeachBatchSink class=md-nav__link> ForeachBatchSink </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-8 type=checkbox id=nav-3-8> <label class=md-nav__link for=nav-3-8> Memory Data Source <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Memory Data Source" data-md-level=2> <label class=md-nav__title for=nav-3-8> <span class="md-nav__icon md-icon"></span> Memory Data Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-memory-data-source/ title="Memory Data Source" class=md-nav__link> Memory Data Source </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MemoryStream/ title=MemoryStream class=md-nav__link> MemoryStream </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-ContinuousMemoryStream/ title=ContinuousMemoryStream class=md-nav__link> ContinuousMemoryStream </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MemorySink/ title=MemorySink class=md-nav__link> MemorySink </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-8-5 type=checkbox id=nav-3-8-5> <label class=md-nav__link for=nav-3-8-5> MemorySinkV2 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=MemorySinkV2 data-md-level=3> <label class=md-nav__title for=nav-3-8-5> <span class="md-nav__icon md-icon"></span> MemorySinkV2 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-streaming-MemorySinkV2/ title=MemorySinkV2 class=md-nav__link> MemorySinkV2 </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MemoryStreamWriter/ title=MemoryStreamWriter class=md-nav__link> MemoryStreamWriter </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MemoryStreamBase/ title=MemoryStreamBase class=md-nav__link> MemoryStreamBase </a> </li> <li class=md-nav__item> <a href=../spark-sql-streaming-MemorySinkBase/ title=MemorySinkBase class=md-nav__link> MemorySinkBase </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Demos <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Demos data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"></span> Demos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../demo/spark-sql-streaming-demo-FlatMapGroupsWithStateExec/ title="Internals of FlatMapGroupsWithStateExec Physical Operator" class=md-nav__link> Internals of FlatMapGroupsWithStateExec Physical Operator </a> </li> <li class=md-nav__item> <a href=../demo/arbitrary-stateful-streaming-aggregation-flatMapGroupsWithState/ title="Arbitrary Stateful Streaming Aggregation with KeyValueGroupedDataset.flatMapGroupsWithState Operator" class=md-nav__link> Arbitrary Stateful Streaming Aggregation with KeyValueGroupedDataset.flatMapGroupsWithState Operator </a> </li> <li class=md-nav__item> <a href=../demo/exploring-checkpointed-state/ title="Exploring Checkpointed State" class=md-nav__link> Exploring Checkpointed State </a> </li> <li class=md-nav__item> <a href=../demo/watermark-aggregation-append/ title="Streaming Watermark with Aggregation in Append Output Mode" class=md-nav__link> Streaming Watermark with Aggregation in Append Output Mode </a> </li> <li class=md-nav__item> <a href=../demo/groupBy-running-count-complete/ title="Streaming Query for Running Counts (Socket Source and Complete Output Mode)" class=md-nav__link> Streaming Query for Running Counts (Socket Source and Complete Output Mode) </a> </li> <li class=md-nav__item> <a href=../demo/kafka-data-source/ title="Streaming Aggregation with Kafka Data Source" class=md-nav__link> Streaming Aggregation with Kafka Data Source </a> </li> <li class=md-nav__item> <a href=../demo/groupByKey-count-Update/ title="groupByKey Streaming Aggregation in Update Mode" class=md-nav__link> groupByKey Streaming Aggregation in Update Mode </a> </li> <li class=md-nav__item> <a href=../demo/StateStoreSaveExec-Complete/ title="StateStoreSaveExec with Complete Output Mode" class=md-nav__link> StateStoreSaveExec with Complete Output Mode </a> </li> <li class=md-nav__item> <a href=../demo/StateStoreSaveExec-Update/ title="StateStoreSaveExec with Update Output Mode" class=md-nav__link> StateStoreSaveExec with Update Output Mode </a> </li> <li class=md-nav__item> <a href=../demo/custom-sink-webui/ title="Developing Custom Streaming Sink (and Monitoring SQL Queries in web UI)" class=md-nav__link> Developing Custom Streaming Sink (and Monitoring SQL Queries in web UI) </a> </li> <li class=md-nav__item> <a href=../demo/current_timestamp/ title="current_timestamp Function For Processing Time in Streaming Queries" class=md-nav__link> current_timestamp Function For Processing Time in Streaming Queries </a> </li> <li class=md-nav__item> <a href=../demo/StreamingQueryManager-awaitAnyTermination-resetTerminated/ title="Using StreamingQueryManager for Query Termination Management" class=md-nav__link> Using StreamingQueryManager for Query Termination Management </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/jaceklaskowski/spark-structured-streaming-book/edit/master/docs/spark-sql-streaming-ProgressReporter.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <p>== [[ProgressReporter]] ProgressReporter Contract</p> <p><code>ProgressReporter</code> is the &lt;<contract, contract>&gt; of &lt;<implementations, stream execution progress reporters>&gt; that report the statistics of execution of a streaming query.</p> <p>[[contract]] .ProgressReporter Contract [cols="30m,70",options="header",width="100%"] |=== | Method | Description</p> <p>| currentBatchId a| [[currentBatchId]]</p> <h2 id=source-scala>[source, scala]<a class=headerlink href=#source-scala title="Permanent link">&para;</a></h2> <h2 id=currentbatchid-long>currentBatchId: Long<a class=headerlink href=#currentbatchid-long title="Permanent link">&para;</a></h2> <p>Id of the current streaming micro-batch</p> <p>| id a| [[id]]</p> <h2 id=source-scala_1>[source, scala]<a class=headerlink href=#source-scala_1 title="Permanent link">&para;</a></h2> <h2 id=id-uuid>id: UUID<a class=headerlink href=#id-uuid title="Permanent link">&para;</a></h2> <p><a href=https://docs.oracle.com/javase/8/docs/api/java/util/UUID.html[Universally>https://docs.oracle.com/javase/8/docs/api/java/util/UUID.html[Universally</a> unique identifier (UUID)] of the streaming query (that stays unchanged between restarts)</p> <p>| lastExecution a| [[lastExecution]]</p> <h2 id=source-scala_2>[source, scala]<a class=headerlink href=#source-scala_2 title="Permanent link">&para;</a></h2> <h2 id=lastexecution-queryexecution>lastExecution: QueryExecution<a class=headerlink href=#lastexecution-queryexecution title="Permanent link">&para;</a></h2> <p><code>QueryExecution</code> of the streaming query</p> <p>| logicalPlan a| [[logicalPlan]]</p> <h2 id=source-scala_3>[source, scala]<a class=headerlink href=#source-scala_3 title="Permanent link">&para;</a></h2> <h2 id=logicalplan-logicalplan>logicalPlan: LogicalPlan<a class=headerlink href=#logicalplan-logicalplan title="Permanent link">&para;</a></h2> <p>Logical query plan of the streaming query</p> <p>Used when <code>ProgressReporter</code> is requested for the following:</p> <ul> <li> <p>&lt;<extractexecutionstats, extract statistics from the most recent query execution>&gt; (to add <code>watermark</code> metric when a &lt;<spark-sql-streaming-eventtimewatermark.md#, streaming watermark>&gt; is used)</p> </li> <li> <p>&lt;<extractsourcetonuminputrows, extractsourcetonuminputrows>&gt;</p> </li> </ul> <p>| name a| [[name]]</p> <h2 id=source-scala_4>[source, scala]<a class=headerlink href=#source-scala_4 title="Permanent link">&para;</a></h2> <h2 id=name-string>name: String<a class=headerlink href=#name-string title="Permanent link">&para;</a></h2> <p>Name of the streaming query</p> <p>| newData a| [[newData]]</p> <h2 id=source-scala_5>[source, scala]<a class=headerlink href=#source-scala_5 title="Permanent link">&para;</a></h2> <h2 id=newdata-mapbasestreamingsource-logicalplan>newData: Map[BaseStreamingSource, LogicalPlan]<a class=headerlink href=#newdata-mapbasestreamingsource-logicalplan title="Permanent link">&para;</a></h2> <p>&lt;<spark-sql-streaming-basestreamingsource.md#, streaming readers and sources>&gt; with the new data (as a <code>LogicalPlan</code>)</p> <p>Used when:</p> <ul> <li><code>ProgressReporter</code> &lt;<extractexecutionstats, extracts statistics from the most recent query execution>&gt; (to calculate the so-called <code>inputRows</code>)</li> </ul> <p>| offsetSeqMetadata a| [[offsetSeqMetadata]]</p> <h2 id=source-scala_6>[source, scala]<a class=headerlink href=#source-scala_6 title="Permanent link">&para;</a></h2> <h2 id=offsetseqmetadata-offsetseqmetadata>offsetSeqMetadata: OffsetSeqMetadata<a class=headerlink href=#offsetseqmetadata-offsetseqmetadata title="Permanent link">&para;</a></h2> <p>&lt;<spark-sql-streaming-offsetseqmetadata.md#, offsetseqmetadata>&gt; (with the current micro-batch &lt;<spark-sql-streaming-offsetseqmetadata.md#batchwatermarkms, event-time watermark>&gt; and &lt;<spark-sql-streaming-offsetseqmetadata.md#batchtimestampms, timestamp>&gt;)</p> <p>| postEvent a| [[postEvent]]</p> <h2 id=source-scala_7>[source, scala]<a class=headerlink href=#source-scala_7 title="Permanent link">&para;</a></h2> <h2 id=posteventevent-streamingquerylistenerevent-unit>postEvent(event: StreamingQueryListener.Event): Unit<a class=headerlink href=#posteventevent-streamingquerylistenerevent-unit title="Permanent link">&para;</a></h2> <p>Posts &lt;<spark-sql-streaming-streamingquerylistener.md#, streamingquerylistener.event>&gt;</p> <p>| runId a| [[runId]]</p> <h2 id=source-scala_8>[source, scala]<a class=headerlink href=#source-scala_8 title="Permanent link">&para;</a></h2> <h2 id=runid-uuid>runId: UUID<a class=headerlink href=#runid-uuid title="Permanent link">&para;</a></h2> <p><a href=https://docs.oracle.com/javase/8/docs/api/java/util/UUID.html[Universally>https://docs.oracle.com/javase/8/docs/api/java/util/UUID.html[Universally</a> unique identifier (UUID)] of the single run of the streaming query (that changes every restart)</p> <p>| sink a| [[sink]]</p> <h2 id=source-scala_9>[source, scala]<a class=headerlink href=#source-scala_9 title="Permanent link">&para;</a></h2> <h2 id=sink-basestreamingsink>sink: BaseStreamingSink<a class=headerlink href=#sink-basestreamingsink title="Permanent link">&para;</a></h2> <p>The one and only &lt;<spark-sql-streaming-basestreamingsink.md#, streaming writer or sink>&gt; of the streaming query</p> <p>| sources a| [[sources]]</p> <h2 id=source-scala_10>[source, scala]<a class=headerlink href=#source-scala_10 title="Permanent link">&para;</a></h2> <h2 id=sources-seqbasestreamingsource>sources: Seq[BaseStreamingSource]<a class=headerlink href=#sources-seqbasestreamingsource title="Permanent link">&para;</a></h2> <p>&lt;<spark-sql-streaming-basestreamingsource.md#, streaming readers and sources>&gt; of the streaming query</p> <p>Used when &lt;<finishtrigger, finishing a trigger (and updating progress and marking current status as trigger inactive)>&gt;</p> <p>| sparkSession a| [[sparkSession]]</p> <h2 id=source-scala_11>[source, scala]<a class=headerlink href=#source-scala_11 title="Permanent link">&para;</a></h2> <h2 id=sparksession-sparksession>sparkSession: SparkSession<a class=headerlink href=#sparksession-sparksession title="Permanent link">&para;</a></h2> <p><code>SparkSession</code> of the streaming query</p> <p>TIP: Read up on <a href=https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-SparkSession.html[SparkSession>https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-SparkSession.html[SparkSession</a>] in <a href=https://bit.ly/spark-sql-internals[The>https://bit.ly/spark-sql-internals[The</a> Internals of Spark SQL] book.</p> <p>| triggerClock a| [[triggerClock]]</p> <h2 id=source-scala_12>[source, scala]<a class=headerlink href=#source-scala_12 title="Permanent link">&para;</a></h2> <h2 id=triggerclock-clock>triggerClock: Clock<a class=headerlink href=#triggerclock-clock title="Permanent link">&para;</a></h2> <p>Clock of the streaming query</p> <p>|===</p> <p>[[implementations]] NOTE: &lt;<spark-sql-streaming-streamexecution.md#, streamexecution>&gt; is the one and only known direct extension of the &lt;<contract, progressreporter contract>&gt; in Spark Structured Streaming.</p> <p>[[noDataProgressEventInterval]] <code>ProgressReporter</code> uses the &lt;<spark-sql-streaming-properties.md#spark.sql.streaming.nodataprogresseventinterval, spark.sql.streaming.nodataprogresseventinterval>&gt; configuration property to control how long to wait between two progress events when there is no data (default: <code>10000L</code>) when &lt;<finishtrigger, finishing trigger>&gt;.</p> <p>[[timestampFormat]] <code>ProgressReporter</code> uses <em>++yyyy-MM-dd'T'HH<img alt=🇲🇲 class=emojione src=https://cdnjs.cloudflare.com/ajax/libs/emojione/2.2.7/assets/png/1f1f2-1f1f2.png title=:mm:>ss.SSS'Z'++</em> time format (with <em>UTC</em> timezone).</p> <h2 id=source-scala_13>[source, scala]<a class=headerlink href=#source-scala_13 title="Permanent link">&para;</a></h2> <p>import org.apache.spark.sql.streaming.Trigger import scala.concurrent.duration._ val sampleQuery = spark .readStream .format("rate") .load .writeStream .format("console") .option("truncate", false) .trigger(Trigger.ProcessingTime(10.seconds)) .start</p> <p>// Using public API import org.apache.spark.sql.streaming.SourceProgress scala&gt; sampleQuery. | lastProgress. | sources. | map { case sp: SourceProgress =&gt; | s"source = ${sp.description} =&gt; endOffset = ${sp.endOffset}" }. | foreach(println) source = RateSource[rowsPerSecond=1, rampUpTimeSeconds=0, numPartitions=8] =&gt; endOffset = 663</p> <p>scala&gt; println(sampleQuery.lastProgress.sources(0)) res40: org.apache.spark.sql.streaming.SourceProgress = { "description" : "RateSource[rowsPerSecond=1, rampUpTimeSeconds=0, numPartitions=8]", "startOffset" : 333, "endOffset" : 343, "numInputRows" : 10, "inputRowsPerSecond" : 0.9998000399920015, "processedRowsPerSecond" : 200.0 }</p> <p>// With a hack import org.apache.spark.sql.execution.streaming.StreamingQueryWrapper val offsets = sampleQuery. asInstanceOf[StreamingQueryWrapper]. streamingQuery. availableOffsets. map { case (source, offset) =&gt; s"source = $source =&gt; offset = $offset" } scala&gt; offsets.foreach(println) source = RateSource[rowsPerSecond=1, rampUpTimeSeconds=0, numPartitions=8] =&gt; offset = 293</p> <hr> <p>[[logging]] [TIP] ==== Configure logging of the &lt;<implementations, concrete stream execution progress reporters>&gt; to see what happens inside a <code>ProgressReporter</code>:</p> <ul> <li>&lt;<spark-sql-streaming-continuousexecution.md#logging, continuousexecution>&gt;</li> </ul> <h1 id=_1>* &lt;<spark-sql-streaming-microbatchexecution.md#logging, microbatchexecution>&gt;<a class=headerlink href=#_1 title="Permanent link">&para;</a></h1> <p>=== [[progressBuffer]] <code>progressBuffer</code> Internal Property</p> <h2 id=source-scala_14>[source, scala]<a class=headerlink href=#source-scala_14 title="Permanent link">&para;</a></h2> <h2 id=progressbuffer-queuestreamingqueryprogress>progressBuffer: Queue[StreamingQueryProgress]<a class=headerlink href=#progressbuffer-queuestreamingqueryprogress title="Permanent link">&para;</a></h2> <p><code>progressBuffer</code> is a <a href=https://www.scala-lang.org/api/2.12.x/scala/collection/mutable/Queue.html[scala.collection.mutable.Queue>https://www.scala-lang.org/api/2.12.x/scala/collection/mutable/Queue.html[scala.collection.mutable.Queue</a>] of &lt;<spark-sql-streaming-streamingqueryprogress.md#, streamingqueryprogresses>&gt;.</p> <p><code>progressBuffer</code> has a new <code>StreamingQueryProgress</code> added when <code>ProgressReporter</code> is requested to &lt;<updateprogress, update progress of a streaming query>&gt;.</p> <p>When the size (the number of <code>StreamingQueryProgresses</code>) is above &lt;<spark-sql-streaming-properties.md#spark.sql.streaming.numrecentprogressupdates, spark.sql.streaming.numrecentprogressupdates>&gt; threshold, the oldest <code>StreamingQueryProgress</code> is removed (<em>dequeued</em>).</p> <p><code>progressBuffer</code> is used when <code>ProgressReporter</code> is requested for the &lt;<lastprogress, last>&gt; and the &lt;<recentprogress, recent streamingqueryprogresses>&gt;</p> <p>=== [[status]] <code>status</code> Method</p> <h2 id=source-scala_15>[source, scala]<a class=headerlink href=#source-scala_15 title="Permanent link">&para;</a></h2> <h2 id=status-streamingquerystatus>status: StreamingQueryStatus<a class=headerlink href=#status-streamingquerystatus title="Permanent link">&para;</a></h2> <p><code>status</code> gives the &lt;<currentstatus, current streamingquerystatus>&gt;.</p> <p>NOTE: <code>status</code> is used when <code>StreamingQueryWrapper</code> is requested for the current status of a streaming query (that is part of spark-sql-streaming-StreamingQuery.md#status[StreamingQuery Contract]).</p> <p>=== [[updateProgress]] Updating Progress of Streaming Query -- <code>updateProgress</code> Internal Method</p> <h2 id=source-scala_16>[source, scala]<a class=headerlink href=#source-scala_16 title="Permanent link">&para;</a></h2> <h2 id=updateprogressnewprogress-streamingqueryprogress-unit>updateProgress(newProgress: StreamingQueryProgress): Unit<a class=headerlink href=#updateprogressnewprogress-streamingqueryprogress-unit title="Permanent link">&para;</a></h2> <p><code>updateProgress</code> records the input <code>newProgress</code> and posts a spark-sql-streaming-StreamingQueryListener.md#QueryProgressEvent[QueryProgressEvent] event.</p> <p>.ProgressReporter's Reporting Query Progress image::images/ProgressReporter-updateProgress.png[align="center"]</p> <p><code>updateProgress</code> adds the input <code>newProgress</code> to &lt;<progressbuffer, progressbuffer>&gt;.</p> <p><code>updateProgress</code> removes elements from &lt;<progressbuffer, progressbuffer>&gt; if their number is or exceeds the value of spark-sql-streaming-properties.md#spark.sql.streaming.numRecentProgressUpdates[spark.sql.streaming.numRecentProgressUpdates] property.</p> <p><code>updateProgress</code> &lt;<postevent, posts a queryprogressevent>&gt; (with the input <code>newProgress</code>).</p> <p><code>updateProgress</code> prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Streaming query made progress: [newProgress]
</code></pre></div> <p>NOTE: <code>updateProgress</code> synchronizes concurrent access to the &lt;<progressbuffer, progressbuffer>&gt; internal registry.</p> <p>NOTE: <code>updateProgress</code> is used exclusively when <code>ProgressReporter</code> is requested to &lt;<finishtrigger, finish up a trigger>&gt;.</p> <p>=== [[startTrigger]] Initializing Query Progress for New Trigger -- <code>startTrigger</code> Method</p> <h2 id=source-scala_17>[source, scala]<a class=headerlink href=#source-scala_17 title="Permanent link">&para;</a></h2> <h2 id=starttrigger-unit>startTrigger(): Unit<a class=headerlink href=#starttrigger-unit title="Permanent link">&para;</a></h2> <p><code>startTrigger</code> prints out the following DEBUG message to the logs:</p> <div class=highlight><pre><span></span><code>Starting Trigger Calculation
</code></pre></div> <p>.startTrigger's Internal Registry Changes For New Trigger [cols="30,70",options="header",width="100%"] |=== | Registry | New Value</p> <p>| &lt;<lasttriggerstarttimestamp, lasttriggerstarttimestamp>&gt; | &lt;<currenttriggerstarttimestamp, currenttriggerstarttimestamp>&gt;</p> <p>| &lt;<currenttriggerstarttimestamp, currenttriggerstarttimestamp>&gt; | Requests the &lt;<triggerclock, trigger clock>&gt; for the current timestamp (in millis)</p> <p>| &lt;<currentstatus, currentstatus>&gt; | Enables (<code>true</code>) the <code>isTriggerActive</code> flag of the &lt;<currentstatus, currentstatus>&gt;</p> <p>| &lt;<currenttriggerstartoffsets, currenttriggerstartoffsets>&gt; | <code>null</code></p> <p>| &lt;<currenttriggerendoffsets, currenttriggerendoffsets>&gt; | <code>null</code></p> <p>| &lt;<currentdurationsms, currentdurationsms>&gt; | Clears the &lt;<currentdurationsms, currentdurationsms>&gt;</p> <p>|===</p> <h1 id=note>[NOTE]<a class=headerlink href=#note title="Permanent link">&para;</a></h1> <p><code>startTrigger</code> is used when:</p> <ul> <li> <p><code>MicroBatchExecution</code> stream execution engine is requested to &lt;<spark-sql-streaming-microbatchexecution.md#runactivatedstream, run an activated streaming query>&gt; (at the &lt;<spark-sql-streaming-microbatchexecution.md#runactivatedstream-starttrigger, beginning of every trigger>&gt;)</p> </li> <li> <p><code>ContinuousExecution</code> stream execution engine is requested to &lt;<spark-sql-streaming-continuousexecution.md#runcontinuous, run an activated streaming query>&gt; (at the beginning of every trigger)</p> </li> </ul> <h1 id=streamexecution-starts-spark-sql-streaming-streamexecutionmdrunstreamrunning-batches-as-part-of-spark-sql-streaming-streamexecutionmdtriggerexecutortriggerexecutor-executing-a-batch-runner><code>StreamExecution</code> starts spark-sql-streaming-StreamExecution.md#runStream[running batches] (as part of spark-sql-streaming-StreamExecution.md#triggerExecutor[TriggerExecutor] executing a batch runner).<a class=headerlink href=#streamexecution-starts-spark-sql-streaming-streamexecutionmdrunstreamrunning-batches-as-part-of-spark-sql-streaming-streamexecutionmdtriggerexecutortriggerexecutor-executing-a-batch-runner title="Permanent link">&para;</a></h1> <p>=== [[finishTrigger]] Finishing Up Streaming Batch (Trigger) and Generating StreamingQueryProgress -- <code>finishTrigger</code> Method</p> <h2 id=source-scala_18>[source, scala]<a class=headerlink href=#source-scala_18 title="Permanent link">&para;</a></h2> <h2 id=finishtriggerhasnewdata-boolean-unit>finishTrigger(hasNewData: Boolean): Unit<a class=headerlink href=#finishtriggerhasnewdata-boolean-unit title="Permanent link">&para;</a></h2> <p>Internally, <code>finishTrigger</code> sets &lt;<currenttriggerendtimestamp, currenttriggerendtimestamp>&gt; to the current time (using &lt;<triggerclock, triggerclock>&gt;).</p> <p><code>finishTrigger</code> &lt;<extractexecutionstats, extractexecutionstats>&gt;.</p> <p><code>finishTrigger</code> calculates the <em>processing time</em> (in seconds) as the difference between the &lt;<currenttriggerendtimestamp, end>&gt; and &lt;<currenttriggerstarttimestamp, start>&gt; timestamps.</p> <p><code>finishTrigger</code> calculates the <em>input time</em> (in seconds) as the difference between the start time of the &lt;<currenttriggerstarttimestamp, current>&gt; and &lt;<lasttriggerstarttimestamp, last>&gt; triggers.</p> <p>.ProgressReporter's finishTrigger and Timestamps image::images/ProgressReporter-finishTrigger-timestamps.png[align="center"]</p> <p><code>finishTrigger</code> prints out the following DEBUG message to the logs:</p> <div class=highlight><pre><span></span><code>Execution stats: [executionStats]
</code></pre></div> <p><code>finishTrigger</code> creates a &lt;<sourceprogress, sourceprogress>&gt; (aka source statistics) for &lt;<sources, every source used>&gt;.</p> <p><code>finishTrigger</code> creates a &lt;<sinkprogress, sinkprogress>&gt; (aka sink statistics) for the &lt;<sink, sink>&gt;.</p> <p><code>finishTrigger</code> creates a spark-sql-streaming-StreamingQueryProgress.md[StreamingQueryProgress].</p> <p>If there was any data (using the input <code>hasNewData</code> flag), <code>finishTrigger</code> resets &lt;<lastnodataprogresseventtime, lastnodataprogresseventtime>&gt; (i.e. becomes the minimum possible time) and &lt;<updateprogress, updates query progress>&gt;.</p> <p>Otherwise, when no data was available (using the input <code>hasNewData</code> flag), <code>finishTrigger</code> &lt;<updateprogress, updates query progress>&gt; only when &lt;<lastnodataprogresseventtime, lastnodataprogresseventtime>&gt; passed.</p> <p>In the end, <code>finishTrigger</code> disables <code>isTriggerActive</code> flag of &lt;<currentstatus, streamingquerystatus>&gt; (i.e. sets it to <code>false</code>).</p> <p>NOTE: <code>finishTrigger</code> is used exclusively when <code>MicroBatchExecution</code> is requested to &lt;<spark-sql-streaming-microbatchexecution.md#runactivatedstream, run the activated streaming query>&gt; (after &lt;<spark-sql-streaming-microbatchexecution.md#runactivatedstream-triggerexecution, triggerexecution phase>&gt; at the end of a streaming batch).</p> <p>=== [[reportTimeTaken]] Time-Tracking Section (Recording Execution Time for Progress Reporting) -- <code>reportTimeTaken</code> Method</p> <h2 id=source-scala_19>[source, scala]<a class=headerlink href=#source-scala_19 title="Permanent link">&para;</a></h2> <p>reportTimeTaken<a href="triggerDetailKey: String">T</a>( body: =&gt; T): T</p> <hr> <p><code>reportTimeTaken</code> measures the time to execute <code>body</code> and records it in the &lt;<currentdurationsms, currentdurationsms>&gt; internal registry under <code>triggerDetailKey</code> key. If the <code>triggerDetailKey</code> key was recorded already, the current execution time is added.</p> <p>In the end, <code>reportTimeTaken</code> prints out the following DEBUG message to the logs and returns the result of executing <code>body</code>.</p> <div class=highlight><pre><span></span><code>[triggerDetailKey] took [time] ms
</code></pre></div> <h1 id=note_1>[NOTE]<a class=headerlink href=#note_1 title="Permanent link">&para;</a></h1> <p><code>reportTimeTaken</code> is used when the &lt;<spark-sql-streaming-streamexecution.md#extensions, stream execution engines>&gt; are requested to execute the following phases (that appear as <code>triggerDetailKey</code> in the DEBUG message in the logs):</p> <ul> <li> <p><code>MicroBatchExecution</code> ** &lt;<spark-sql-streaming-microbatchexecution.md#runactivatedstream-triggerexecution, triggerexecution>&gt; ** &lt;<spark-sql-streaming-microbatchexecution.md#constructnextbatch-getoffset, getoffset>&gt; ** &lt;<spark-sql-streaming-microbatchexecution.md#constructnextbatch-setoffsetrange, setoffsetrange>&gt; ** &lt;<spark-sql-streaming-microbatchexecution.md#constructnextbatch-getendoffset, getendoffset>&gt; ** &lt;<spark-sql-streaming-microbatchexecution.md#constructnextbatch-walcommit, walcommit>&gt; ** &lt;<spark-sql-streaming-microbatchexecution.md#runbatch-getbatch, getbatch>&gt; ** &lt;<spark-sql-streaming-microbatchexecution.md#runbatch-queryplanning, queryplanning>&gt; ** &lt;<spark-sql-streaming-microbatchexecution.md#runbatch-addbatch, addbatch>&gt;</p> </li> <li> <p><code>ContinuousExecution</code> ** &lt;<spark-sql-streaming-continuousexecution.md#runcontinuous-queryplanning, queryplanning>&gt; ** &lt;<spark-sql-streaming-continuousexecution.md#runcontinuous-runcontinuous, runcontinuous>&gt; ====</p> </li> </ul> <p>=== [[updateStatusMessage]] Updating Status Message -- <code>updateStatusMessage</code> Method</p> <h2 id=source-scala_20>[source, scala]<a class=headerlink href=#source-scala_20 title="Permanent link">&para;</a></h2> <h2 id=updatestatusmessagemessage-string-unit>updateStatusMessage(message: String): Unit<a class=headerlink href=#updatestatusmessagemessage-string-unit title="Permanent link">&para;</a></h2> <p><code>updateStatusMessage</code> simply updates the <code>message</code> in the &lt;<currentstatus, streamingquerystatus>&gt; internal registry.</p> <h1 id=note_2>[NOTE]<a class=headerlink href=#note_2 title="Permanent link">&para;</a></h1> <p><code>updateStatusMessage</code> is used when:</p> <ul> <li><code>StreamExecution</code> is requested to &lt;<spark-sql-streaming-streamexecution.md#runstream, run stream processing>&gt;</li> </ul> <h1 id=microbatchexecution-is-requested-to>* <code>MicroBatchExecution</code> is requested to &lt;<spark-sql-streaming-microbatchexecution.md#runactivatedstream, run an activated streaming query>&gt;, &lt;<spark-sql-streaming-microbatchexecution.md#constructnextbatch, construct the next streaming micro-batch>&gt;<a class=headerlink href=#microbatchexecution-is-requested-to title="Permanent link">&para;</a></h1> <p>=== [[extractExecutionStats]] Generating Execution Statistics -- <code>extractExecutionStats</code> Internal Method</p> <h2 id=source-scala_21>[source, scala]<a class=headerlink href=#source-scala_21 title="Permanent link">&para;</a></h2> <h2 id=extractexecutionstatshasnewdata-boolean-executionstats>extractExecutionStats(hasNewData: Boolean): ExecutionStats<a class=headerlink href=#extractexecutionstatshasnewdata-boolean-executionstats title="Permanent link">&para;</a></h2> <p><code>extractExecutionStats</code> generates an &lt;<spark-sql-streaming-executionstats.md#, executionstats>&gt; of the &lt;<lastexecution, last execution>&gt; of the streaming query.</p> <p>Internally, <code>extractExecutionStats</code> generate <em>watermark</em> metric (using the &lt;<spark-sql-streaming-offsetseqmetadata.md#batchwatermarkms, event-time watermark>&gt; of the &lt;<offsetseqmetadata, offsetseqmetadata>&gt;) if there is a &lt;<spark-sql-streaming-eventtimewatermark.md#, eventtimewatermark>&gt; unary logical operator in the &lt;<logicalplan, logical plan>&gt; of the streaming query.</p> <p>NOTE: &lt;<spark-sql-streaming-eventtimewatermark.md#, eventtimewatermark>&gt; unary logical operator represents <a href=../operators/withWatermark/ >Dataset.withWatermark</a> operator in a streaming query.</p> <p><code>extractExecutionStats</code> &lt;<extractstateoperatormetrics, extractstateoperatormetrics>&gt;.</p> <p><code>extractExecutionStats</code> &lt;<extractsourcetonuminputrows, extractsourcetonuminputrows>&gt;.</p> <p><code>extractExecutionStats</code> finds the &lt;<spark-sql-streaming-eventtimewatermarkexec.md#, eventtimewatermarkexec>&gt; unary physical operator (with non-zero &lt;<spark-sql-streaming-eventtimestatsaccum.md#, eventtimestats>&gt;) and generates <em>max</em>, <em>min</em>, and <em>avg</em> statistics.</p> <p>In the end, <code>extractExecutionStats</code> creates a &lt;<spark-sql-streaming-executionstats.md#, executionstats>&gt; with the execution statistics.</p> <p>If the input <code>hasNewData</code> flag is turned off (<code>false</code>), <code>extractExecutionStats</code> returns an &lt;<spark-sql-streaming-executionstats.md#, executionstats>&gt; with no input rows and event-time statistics (that require data to be processed to have any sense).</p> <p>NOTE: <code>extractExecutionStats</code> is used exclusively when <code>ProgressReporter</code> is requested to &lt;<finishtrigger, finish up a streaming batch (trigger) and generate a streamingqueryprogress>&gt;.</p> <p>=== [[extractStateOperatorMetrics]] Generating StateStoreWriter Metrics (StateOperatorProgress) -- <code>extractStateOperatorMetrics</code> Internal Method</p> <h2 id=source-scala_22>[source, scala]<a class=headerlink href=#source-scala_22 title="Permanent link">&para;</a></h2> <p>extractStateOperatorMetrics( hasNewData: Boolean): Seq[StateOperatorProgress]</p> <hr> <p><code>extractStateOperatorMetrics</code> requests the &lt;<lastexecution, queryexecution>&gt; for the optimized execution plan (<code>executedPlan</code>) and finds all &lt;<spark-sql-streaming-statestorewriter.md#, statestorewriter>&gt; physical operators and requests them for &lt;<spark-sql-streaming-statestorewriter.md#getprogress, stateoperatorprogress>&gt;.</p> <p><code>extractStateOperatorMetrics</code> clears (<em>zeros</em>) the <em>numRowsUpdated</em> metric for the given <code>hasNewData</code> turned off (<code>false</code>).</p> <p><code>extractStateOperatorMetrics</code> returns an empty collection for the &lt;<lastexecution, queryexecution>&gt; uninitialized (<code>null</code>).</p> <p>NOTE: <code>extractStateOperatorMetrics</code> is used exclusively when <code>ProgressReporter</code> is requested to &lt;<extractexecutionstats, generate execution statistics>&gt;.</p> <p>=== [[extractSourceToNumInputRows]] <code>extractSourceToNumInputRows</code> Internal Method</p> <h2 id=source-scala_23>[source, scala]<a class=headerlink href=#source-scala_23 title="Permanent link">&para;</a></h2> <h2 id=extractsourcetonuminputrows-mapbasestreamingsource-long>extractSourceToNumInputRows(): Map[BaseStreamingSource, Long]<a class=headerlink href=#extractsourcetonuminputrows-mapbasestreamingsource-long title="Permanent link">&para;</a></h2> <p><code>extractSourceToNumInputRows</code>...FIXME</p> <p>NOTE: <code>extractSourceToNumInputRows</code> is used exclusively when <code>ProgressReporter</code> is requested to &lt;<extractexecutionstats, generate execution statistics>&gt;.</p> <p>=== [[formatTimestamp]] <code>formatTimestamp</code> Internal Method</p> <h2 id=source-scala_24>[source, scala]<a class=headerlink href=#source-scala_24 title="Permanent link">&para;</a></h2> <h2 id=formattimestampmillis-long-string>formatTimestamp(millis: Long): String<a class=headerlink href=#formattimestampmillis-long-string title="Permanent link">&para;</a></h2> <p><code>formatTimestamp</code>...FIXME</p> <p>NOTE: <code>formatTimestamp</code> is used when...FIXME</p> <p>=== [[recordTriggerOffsets]] Recording Trigger Offsets (StreamProgress) -- <code>recordTriggerOffsets</code> Method</p> <h2 id=source-scala_25>[source, scala]<a class=headerlink href=#source-scala_25 title="Permanent link">&para;</a></h2> <p>recordTriggerOffsets( from: StreamProgress, to: StreamProgress): Unit</p> <hr> <p><code>recordTriggerOffsets</code> simply sets (<em>records</em>) the &lt;<currenttriggerstartoffsets, currenttriggerstartoffsets>&gt; and &lt;<currenttriggerendoffsets, currenttriggerendoffsets>&gt; internal registries to the &lt;<spark-sql-streaming-offset.md#json, json>&gt; representations of the <code>from</code> and <code>to</code> &lt;<spark-sql-streaming-streamprogress.md#, streamprogresses>&gt;.</p> <h1 id=note_3>[NOTE]<a class=headerlink href=#note_3 title="Permanent link">&para;</a></h1> <p><code>recordTriggerOffsets</code> is used when:</p> <ul> <li><code>MicroBatchExecution</code> is requested to &lt;<spark-sql-streaming-microbatchexecution.md#runactivatedstream, run the activated streaming query>&gt;</li> </ul> <h1 id=continuousexecution-is-requested-to>* <code>ContinuousExecution</code> is requested to &lt;<spark-sql-streaming-continuousexecution.md#commit, commit an epoch>&gt;<a class=headerlink href=#continuousexecution-is-requested-to title="Permanent link">&para;</a></h1> <p>=== [[lastProgress]] Last StreamingQueryProgress -- <code>lastProgress</code> Method</p> <h2 id=source-scala_26>[source, scala]<a class=headerlink href=#source-scala_26 title="Permanent link">&para;</a></h2> <h2 id=lastprogress-streamingqueryprogress>lastProgress: StreamingQueryProgress<a class=headerlink href=#lastprogress-streamingqueryprogress title="Permanent link">&para;</a></h2> <p><code>lastProgress</code>...FIXME</p> <p>NOTE: <code>lastProgress</code> is used when...FIXME</p> <p>=== [[recentProgress]] <code>recentProgress</code> Method</p> <h2 id=source-scala_27>[source, scala]<a class=headerlink href=#source-scala_27 title="Permanent link">&para;</a></h2> <h2 id=recentprogress-arraystreamingqueryprogress>recentProgress: Array[StreamingQueryProgress]<a class=headerlink href=#recentprogress-arraystreamingqueryprogress title="Permanent link">&para;</a></h2> <p><code>recentProgress</code>...FIXME</p> <p>NOTE: <code>recentProgress</code> is used when...FIXME</p> <p>=== [[internal-properties]] Internal Properties</p> <p>[cols="30m,70",options="header",width="100%"] |=== | Name | Description</p> <p>| currentDurationsMs a| [[currentDurationsMs]] <a href=http://www.scala-lang.org/api/2.11.11/index.html#scala.collection.mutable.HashMap[scala.collection.mutable.HashMap>http://www.scala-lang.org/api/2.11.11/index.html#scala.collection.mutable.HashMap[scala.collection.mutable.HashMap</a>] of action names (aka <em>triggerDetailKey</em>) and their cumulative times (in milliseconds).</p> <p>Starts empty when <code>ProgressReporter</code> &lt;<starttrigger, sets the state for a new batch>&gt; with new entries added or updated when &lt;<reporttimetaken, reporting execution time>&gt; (of an action).</p> <h1 id=tip>[TIP]<a class=headerlink href=#tip title="Permanent link">&para;</a></h1> <p>You can see the current value of <code>currentDurationsMs</code> in progress reports under <code>durationMs</code>.</p> <h2 id=optionswrap>[options="wrap"]<a class=headerlink href=#optionswrap title="Permanent link">&para;</a></h2> <p>scala&gt; query.lastProgress.durationMs res3: java.util.Map[String,Long] = {triggerExecution=60, queryPlanning=1, getBatch=5, getOffset=0, addBatch=30, walCommit=23}</p> <hr> <p>====</p> <p>| currentStatus a| [[currentStatus]] &lt;<spark-sql-streaming-streamingquerystatus.md#, streamingquerystatus>&gt; with the current status of the streaming query</p> <p>Available using &lt;<status, status>&gt; method</p> <ul> <li><code>message</code> updated with &lt;<updatestatusmessage, updatestatusmessage>&gt;</li> </ul> <p>| currentTriggerEndOffsets a| [[currentTriggerEndOffsets]]</p> <p>| currentTriggerEndTimestamp a| [[currentTriggerEndTimestamp]] Timestamp of when the current batch/trigger has ended</p> <p>Default: <code>-1L</code></p> <p>| currentTriggerStartOffsets a| [[currentTriggerStartOffsets]]</p> <h2 id=source-scala_28>[source, scala]<a class=headerlink href=#source-scala_28 title="Permanent link">&para;</a></h2> <h2 id=currenttriggerstartoffsets-mapbasestreamingsource-string>currentTriggerStartOffsets: Map[BaseStreamingSource, String]<a class=headerlink href=#currenttriggerstartoffsets-mapbasestreamingsource-string title="Permanent link">&para;</a></h2> <p>Start offsets (in &lt;<spark-sql-streaming-offset.md#json, json format>&gt;) per &lt;<spark-sql-streaming-basestreamingsource.md#, source>&gt;</p> <p>Used exclusively when &lt;<finishtrigger, finishing up a streaming batch (trigger) and generating streamingqueryprogress>&gt; (for a &lt;<spark-sql-streaming-sourceprogress.md#, sourceprogress>&gt;)</p> <p>Reset (<code>null</code>) when &lt;<starttrigger, initializing a query progress for a new trigger>&gt;</p> <p>Initialized when &lt;<recordtriggeroffsets, recording trigger offsets (streamprogress)>&gt;</p> <p>| currentTriggerStartTimestamp a| [[currentTriggerStartTimestamp]] Timestamp of when the current batch/trigger has started</p> <p>Default: <code>-1L</code></p> <p>| lastNoDataProgressEventTime a| [[lastNoDataProgressEventTime]]</p> <p>Default: <code>Long.MinValue</code></p> <p>| lastTriggerStartTimestamp a| [[lastTriggerStartTimestamp]] Timestamp of when the last batch/trigger started</p> <p>Default: <code>-1L</code></p> <p>| metricWarningLogged a| [[metricWarningLogged]] Flag to...FIXME</p> <p>Default: <code>false</code></p> <p>|===</p> <hr> <div class=md-source-date> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">September 17, 2020</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=../spark-sql-streaming-StreamingQueryListener/ title=StreamingQueryListener class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> StreamingQueryListener </div> </div> </a> <a href=../spark-sql-streaming-StreamingQueryProgress/ title=StreamingQueryProgress class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> StreamingQueryProgress </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener>Jacek Laskowski</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/jaceklaskowski target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/jaceklaskowski target=_blank rel=noopener title=linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../assets/javascripts/vendor.2d1db4bd.min.js></script> <script src=../assets/javascripts/bundle.6627ddf3.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script> <script>
        app = initialize({
          base: "..",
          features: ['tabs', 'instant'],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.5eca75d3.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> </body> </html>